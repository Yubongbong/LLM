# LLaMA 7B Chat ëª¨ë¸ íŒŒì¸íŠœë‹-Step by Step

---

## ëª©í‘œ

- QLoRA ê¸°ë²•ì„ í™œìš©í•˜ì—¬ ë‚˜ë§Œì˜ ë°ì´í„°ì…‹ì„ íŒŒì¸íŠœë‹í•˜ì—¬ í—ˆê¹…í˜ì´ìŠ¤ì— ë°°í¬í•´ë³´ê¸°

### ê²½ì œì ì¸ íŒŒì¸íŠœë‹ì„ ìœ„í•œ PEFTì™€ QLoRA ê¸°ë²•

- íŒŒì¸íŠœë‹ì„ ì§„í–‰í•  ë•Œ ëª¨ë¸ ì „ì²´ì˜ íŒŒë¼ë¯¸í„°ë¥¼ ìˆ˜ì •í•˜ì§€ ì•Šê³  ì¼ë¶€ íŒŒë¼ë¯¸í„°ë§Œ ì—…ë°ì´íŠ¸ë¥¼ í•˜ë”ë¼ë„ ì „ì²´ íŒŒë¼ë¯¸í„°ë¥¼ ìˆ˜ì •í–ˆì„ ë•Œì— ì¤€í•˜ëŠ” ìˆ˜ì¤€ì˜ ì„±ëŠ¥ì„ ê¸°ëŒ€í•  ìˆ˜ ìˆì„ ì •ë„ë¡œ ê°„ì†Œí™”ëœ ê¸°ë²•ì´ ëŒ€ì¤‘í™” ë˜ê³  ìˆë‹¤.
- **PEFT(Parameter Efficient Fine-tuning)**ëŠ” ëª¨ë¸ ì „ì²´ì˜ íŒŒë¼ë¯¸í„°ë¥¼ íŠœë‹í•  í•„ìš”ê°€ ì—†ì´, ì¼ë¶€ íŒŒë¼ë¯¸í„°ë¥¼ íŠœë‹í•˜ë”ë¼ë„ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ ì ì€ ìì›ìœ¼ë¡œ íŠœë‹í•  ìˆ˜ ìˆë„ë¡ í•˜ëŠ” ë°©ë²•ì„ ì˜ë¯¸í•œë‹¤.
- **PEFT**ì—ëŠ” **LoRA(Low Rank Adapation)** ê¸°ë²•ì´ ì£¼ë¡œ ì‚¬ìš©ë˜ê³  ìˆê³ , ìµœê·¼ì—ëŠ” **QLoRA** ê¸°ë²•ì´ ì œì‹œë˜ê³  ìˆë‹¤.

### LoRA

- LoRAëŠ” ê³ ì • ê°€ì¤‘ì¹˜ë¥¼ ê°€ì§€ê³  ìˆëŠ” **Pretrained ëœ ëª¨ë¸**ì„ ê¸°ë°˜ìœ¼ë¡œ ì¶”ê°€ í•™ìŠµì´ ê°€ëŠ¥í•œ Rank Decomposition í–‰ë ¬ì„ íŠ¸ëœìŠ¤í¬ë¨¸ ì•„í‚¤í…ì²˜ì˜ ê° ë ˆì´ì–´ì— ë¶™ì¸ ê²ƒì´ë‹¤. ì¦‰, í›ˆë ¨ ê°€ëŠ¥í•œ ë ˆì´ì–´ë¥¼ ì¶”ê°€í•´ì„œ ë³„ë„ì˜ í›ˆë ¨ì„ í†µí•´ í•™ìŠµì‹œí‚¨ ê²ƒì´ë‹¤.

  ![image-20240322092239619](./../img/image-20240322092239619.png)

- LoRAëŠ” Low Data Regimeì²˜ëŸ¼ ë°ì´í„°ê°€ ì ì€ ìƒí™©ì—ì„œë„ íŒŒì¸íŠœë‹í•˜ê¸° ìš©ì´í•˜ë‹¤ëŠ” ì¥ì ì´ ìˆë‹¤.

- ìš°ë¦¬ê°€ LoRAë¥¼ í†µí•´ í•™ìŠµí•œ ê°€ì¤‘ì¹˜ëŠ” ì‘ì€ ì–‘ì´ì§€ë§Œ ì‚¬ì „ í•™ìŠµëœ LLM ëª¨ë¸ ë ˆì´ì–´ì˜ ë§¨ ìœ— ë¶€ë¶„ì„ ì°¨ì§€í•˜ê²Œ ë˜ë©°, ë‹¤ë¥¸ íŒŒë¼ë¯¸í„°ì— ì–¼ë§ˆë‚˜ ì˜í–¥ì„ ì¤„ ì§€ hyper parameterë¥¼ ì ì ˆíˆ ì„¤ì •í•¨ìœ¼ë¡œì„œ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ ê²°ì •í•  ìˆ˜ ìˆë‹¤.

- ìµœê·¼ì—ëŠ” QLoRAë¼ëŠ” 4ë¹„íŠ¸ ì–‘ìí™” ê¸°ë²•ì´ ì£¼ëª©ì„ ë°›ìœ¼ë©° LLM ëª¨ë¸ì˜ ì ì€ ë¹„íŠ¸ì˜ í¬ë§·ìœ¼ë¡œ ì„¤ì •í•˜ì—¬ í° ë©”ëª¨ë¦¬ì˜ GPU ì—†ì´ë„ íŒŒì¸íŠœë‹ì´ ê°€ëŠ¥í•˜ê²Œ ë˜ì—ˆë‹¤.

- ê±°ëŒ€ ì–¸ì–´ëª¨ë¸ì˜ íŒŒë¼ë¯¸í„° ì‚¬ì´ì¦ˆê°€ ì»¤ì ¸ê°€ëŠ” ì™€ì¤‘ì—ì„œë„ ì ì ˆí•œ ì–‘ìí™”ì™€ distillationì„ í†µí•´ ëª¨ë¸ì— ì €ì¥ë˜ê³  ë©”ëª¨ë¦¬ì— ë¡œë“œë˜ëŠ” ë¶€ë‹´ì„ ì¤„ì¸ë‹¤.

- QLoRAëŠ” LoRAì˜ ê°€ì¤‘ì¹˜ë¥¼ **NormalFloat** ì´ë¼ëŠ” **FP4ë¥¼ ë³€í˜•í•œ ìë£Œí˜•**ì„ ì‚¬ìš©í•˜ì—¬ **4ë¹„íŠ¸ ì–‘ìí™”**ë¥¼ í•œë‹¤.

- í•´ë‹¹ ìë£Œí˜•ì€ ë¹„ì„ í˜•ì ì¸ ê°„ê²©ê³¼ ë¹„ëŒ€ì¹­ ë¶„í¬ë¥¼ ë°”íƒ•ìœ¼ë¡œ -1ë¶€í„° 1ê¹Œì§€ì˜ ë²”ìœ„ë¥¼ ë‚˜íƒ€ë‚´ì„œ ì €ì¥í•œë‹¤.

-  ì–‘ìí™”ë¥¼ í†µí•´ ì‚¬ì´ì¦ˆë¥¼ ì¤„ì´ë©´ì„œë„ íŠ¸ë ˆì´ë‹ì´ë‚˜ ì—­ì „íŒŒ ê³¼ì •ì—ì„œëŠ” ì—­ì–‘ìí™” ê³¼ì •ì„ ìˆ˜í–‰í•˜ì—¬ **ì €ìˆ˜ì¤€ì˜ ë¹„íŠ¸ë¥¼ 32ë¹„íŠ¸ë¡œ ê·¼ì‚¬í•˜ì—¬ ì¼ì •í•œ ì„±ëŠ¥ì„ ìœ ì§€**í•  ìˆ˜ ìˆë‹¤.

  ![image-20240322092915771](./../img/image-20240322092915771.png)

- ìœ„ í…Œì´ë¸”ì„ ë³´ë©´ QLoRA ê¸°ë²•ì„ í™œìš©í•˜ì˜€ì„ ë•Œ ì¼ë°˜ì ì¸ LoRA íŒŒì¸íŠœë‹ ê¸°ë²•ë³´ë‹¤ ëª¨ë¸ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì´ ì ì€ ê²ƒì„ í™•ì¸, ì–‘ìí™”ê°€ ì¸ë©”ëª¨ë¦¬ ë¡œë“œ ë¶€ë‹´ì„ ì ˆê°ì‹œí‚¤ëŠ”ë° ìƒë‹¹í•œ íš¨ê³¼ê°€ ìˆìŒì„ ê³ ë ¤í•œë‹¤ë©´ ê°€ì„±ë¹„ ëŒ€ë¹„ íš¨ê³¼ì ì´ë¼ê³  í•  ìˆ˜ ìˆë‹¤.

### Step 1. ë¼ì´ë¸ŒëŸ¬ë¦¬ Import

```py
import os  # os ëª¨ë“ˆ ìš´ì˜ì²´ì œì™€ ìƒí˜¸ ì‘ìš©í•  ìˆ˜ ìˆëŠ” ê¸°ëŠ¥ì„ ì œê³µ
import torch # PyTorch ë¼ì´ë¸ŒëŸ¬ë¦¬ë¡œ, ì£¼ë¡œ ë”¥ëŸ¬ë‹ê³¼ ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ì„ êµ¬ì¶•, í•™ìŠµ, í…ŒìŠ¤íŠ¸í•˜ëŠ” ë° ì‚¬ìš©
from datasets import load_dataset  # ë°ì´í„°ì…‹ì„ ì‰½ê²Œ ë¶ˆëŸ¬ì˜¤ê³  ì²˜ë¦¬í•  ìˆ˜ ìˆëŠ” ê¸°ëŠ¥ì„ ì œê³µ
from transformers import (
    AutoModelForCausalLM, # ì¸ê³¼ì  ì–¸ì–´ ì¶”ë¡ (ì˜ˆ: GPT)ì„ ìœ„í•œ ëª¨ë¸ì„ ìë™ìœ¼ë¡œ ë¶ˆëŸ¬ì˜¤ëŠ” í´ë˜ìŠ¤
    AutoTokenizer, # ì…ë ¥ ë¬¸ì¥ì„ í† í° ë‹¨ìœ„ë¡œ ìë™ìœ¼ë¡œ ì˜ë¼ì£¼ëŠ” ì—­í•  
    BitsAndBytesConfig, # ëª¨ë¸ êµ¬ì„±
    HfArgumentParser,  # íŒŒë¼ë¯¸í„° íŒŒì‹±
    TrainingArguments,  # í›ˆë ¨ ì„¤ì •
    pipeline,  # íŒŒì´í”„ë¼ì¸ ì„¤ì •
    logging,  #ë¡œê¹…ì„ ìœ„í•œ í´ë˜ìŠ¤
)

# ëª¨ë¸ íŠœë‹ì„ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬
from peft import LoraConfig, PeftModel  
from trl import SFTTrainer
```

- ë¼ì´ë¸ŒëŸ¬ë¦¬ `BitAndBytes`ê°€ ì•ì„œ ì‚´í´ë³´ì•˜ë˜ ë²¡í„°ì˜ INT8 ìµœëŒ€ ì ˆëŒ€ê°’ ì–‘ìí™” ê¸°ë²•ì„ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ ë„ì™€ì£¼ëŠ” MetaAIì˜ ë¼ì´ë¸ŒëŸ¬ë¦¬

### Step 2. Llama 2 ëª¨ë¸ê³¼ ë°ì´í„° ê°€ì ¸ì˜¤ê¸° ğŸ¤—

```py
# Hugging Face í—ˆë¸Œì—ì„œ í›ˆë ¨í•˜ê³ ì í•˜ëŠ” ëª¨ë¸ì„ ê°€ì ¸ì™€ì„œ ì´ë¦„ ì§€ì •
model_name = "NousResearch/Llama-2-7b-chat-hf"  

# instruction ë°ì´í„° ì„¸íŠ¸ ì„¤ì •
dataset_name = "mlabonne/guanaco-llama2-1k"

# fine-tuning(ë¯¸ì„¸ ì¡°ì •)ì„ ê±°ì¹œ í›„ì˜ ëª¨ë¸ì— ë¶€ì—¬ë  ìƒˆë¡œìš´ ì´ë¦„ì„ ì§€ì •í•˜ëŠ” ë³€ìˆ˜
new_model = "llama-2-7b-yubong" 
```

- Pretrainedëœ ë² ì´ìŠ¤ ëª¨ë¸ Llama 2ì˜ 7B Chat ëª¨ë¸ ì„ íƒ

- [1000ê°œ dataset](https://huggingface.co/datasets/mlabonne/guanaco-llama2-1k) 

### Step 3.  LoRA (Low-Rank Adaptaition) íŒŒë¼ë¯¸í„° ì„¤ì •

```py
# LoRAì—ì„œ ì‚¬ìš©í•˜ëŠ” low-rank matrices ì–´í…ì…˜ ì°¨ì›ì„ ì •ì˜. ì—¬ê¸°ì„œëŠ” 64ë¡œ ì„¤ì •
# ê°’ì´ í¬ë©´ í´ìˆ˜ë¡ ë” ë§ì€ ìˆ˜ì •ì´ ì´ë£¨ì–´ì§€ë©°, ëª¨ë¸ì´ ë” ë³µì¡í•´ì§ˆ ìˆ˜ ìˆìŒ
lora_r = 64   

# LoRA ì ìš© ì‹œ ê°€ì¤‘ì¹˜ì— ê³±í•´ì§€ëŠ” ìŠ¤ì¼€ì¼ë§ ìš”ì†Œ. ì—¬ê¸°ì„œëŠ” 16ìœ¼ë¡œ ì„¤ì •
# LoRAê°€ ì ìš©ë  ë•Œ ì›ë˜ ëª¨ë¸ì˜ ê°€ì¤‘ì¹˜ì— ì–¼ë§ˆë‚˜ ì˜í–¥ì„ ë¯¸ì¹ ì§€ ê²°ì •. ë†’ì€ ê°’ì€ ê°€ì¤‘ì¹˜ ì¡°ì •ì˜ ê°•ë„ë¥¼ ì¦ê°€ì‹œí‚´
lora_alpha = 16  

# Dropout probability for LoRA layers   # LoRA ì¸µì— ì ìš©ë˜ëŠ” ë“œë¡­ì•„ì›ƒ í™•ë¥ . ì—¬ê¸°ì„œëŠ” 0.1 (10%)ë¡œ ì„¤ì •
lora_dropout = 0.1 # ì¼ë¶€ ë„¤íŠ¸ì›Œí¬ ì—°ê²°ì„ ë¬´ì‘ìœ„ë¡œ ë¹„í™œì„±í™”í•˜ì—¬ ëª¨ë¸ì˜ ê°•ê±´í•¨ì— ê¸°ì—¬
```

- ê°€ì¤‘ì¹˜ë¥¼ ì¡°ì •í•˜ì—¬ ë” ì¢‹ì€ ì„±ëŠ¥ì„ ë‚´ì–´ ì¶”ê°€ì ì¸ ì‘ì—…ì— ë” ì˜ ë§ë„ë¡ í•˜ëŠ” ê¸°ë²•ìœ¼ë¡œ ì´ëŠ” ëª¨ë¸ì˜ ì „ì²´ êµ¬ì¡°ë¥¼ ë³€ê²½í•˜ì§€ ì•Šìœ¼ë©´ì„œë„ íš¨ìœ¨ì ìœ¼ë¡œ ëª¨ë¸ì„ ì¡°ì •í•  ìˆ˜ ìˆë‹¤ëŠ” ì¥ì ì´ ìˆìŒ
- `lora_r`ì€ ì •ë³´ì˜ ì†ì‹¤ê³¼ íš¨ìœ¨ì„± ì‚¬ì´ì— ê· í˜•ì„ ë§ì¶”ê¸° ìœ„í•´ ì—¬ëŸ¬ ì‹œë„ë¥¼ í†µí•´ ê²°ì •í•  ìˆ˜ ìˆëŠ” íŒŒë¼ë¯¸í„°ë¡œ ëª¨ë¸ì˜ ê°€ì¤‘ì¹˜ í–‰ë ¬ì„ ë‘ ê°œì˜ low-rank í–‰ë ¬ì˜ ê³±ìœ¼ë¡œ ê·¼ì‚¬í•˜ê¸° ë•Œë¬¸ì—, `lora_r`ì˜ ê°’ì´ ì»¤ì§ˆ ìˆ˜ë¡ ë” ë§ì€ ì •ë³´ë¥¼ ìœ ì§€í•˜ë©´ì„œ ëª¨ë¸ì´ í›ˆë ¨ ë°ì´í„°ì— ê³¼ë„í•˜ê²Œ ì ì‘í•˜ê²Œ í•˜ì—¬ ì˜¤ë¹„í”¼íŒ…ì˜ ê°€ëŠ¥ì„±ì„ ë†’íŒë‹¤.
- í•œí¸ìœ¼ë¡œ `lora_r`ì˜ ê°’ì´ ë‚®ì„ ìˆ˜ë¡ ì •ë³´ê°€ ì†ì‹¤ë˜ë©° ëª¨ë¸ì´ ë°ì´í„°ì˜ ë³µì¡í•œ íŠ¹ì„±ì„ í¬ì°©í•  ê°€ëŠ¥ì„±ì„ ë‚®ì¶˜ë‹¤.
- `lora_alpha`ëŠ” LoRA ê¸°ë²•ì„ ì ìš©í•  ë•Œ ê°€ì¤‘ì¹˜ì— ê³±í•´ì§€ëŠ” scaling factorë¡œì„œ ì›ë˜ì˜ ëª¨ë¸ì— ëŒ€ë¹„í•˜ì—¬ LoRA ê°€ì¤‘ì¹˜ì— ì–¼ë§ˆë‚˜ ì˜í–¥ì„ ë¯¸ì¹ ì§€ë¥¼ ê²°ì •í•œë‹¤.
- `lora_dropout` íŒŒë¼ë¯¸í„°ëŠ” ì „í†µì ì¸ ë¨¸ì‹ ëŸ¬ë‹ì—ì„œ ê³¼ì í•©ì„ ë°©ì§€í•˜ê¸° ìœ„í•˜ì—¬ í›ˆë ¨ ê³¼ì •ì—ì„œ ë„¤íŠ¸ì›Œí¬ì˜ ì¼ë¶€ ê°€ì¤‘ì¹˜ë¥¼ 0ìœ¼ë¡œ ì„¤ì •í•˜ëŠ” ë°©ë²•ì„ ì ìš©í•˜ê¸° ìœ„í•˜ì—¬ ì“°ì¸ë‹¤. ê°€ì¤‘ì¹˜ í–‰ë ¬ì„ ì¡°ì •í•  ë•Œ low-rank matricesë¡œ ê°€ì¤‘ì¹˜ í–‰ë ¬ì„ ê·¼ì‚¬í•˜ëŠ”ë° ì´ ë•Œ LoRA ë³€í™”ëŸ‰ì„ ëª¨ë¸ì— ì ìš©í•˜ê¸° ì „ì— ì¼ë¶€ ì›ì†Œë¥¼ ì„ì˜ë¡œ 0ìœ¼ë¡œ ë§Œë“œëŠ” ë°©ë²•ì´ë‹¤.

### Step 4. `bitsandbytes` íŒŒë¼ë¯¸í„° ì„¤ì •

```py
# 4-bit precision ê¸°ë°˜ì˜ ëª¨ë¸ ë¡œë“œ
use_4bit = True 

# 4ë¹„íŠ¸ ê¸°ë°˜ ëª¨ë¸ì— ëŒ€í•œ dtype ê³„ì‚°
bnb_4bit_compute_dtype = "float16" 

# ì–‘ìí™” ìœ í˜•(fp4 ë˜ëŠ” nf4)
bnb_4bit_quant_type = "nf4" 

# 4ë¹„íŠ¸ ê¸° ëª¨ë¸ì— ëŒ€í•´ ì¤‘ì²© ì–‘ìí™” í™œì„±í™”(ì´ì¤‘ ì–‘ìí™”)
use_nested_quant = False 
```

- `bitsandbytes`ëŠ” QLoRA ê¸°ë²•ì„ ì ìš©í•˜ê¸° ìœ„í•˜ì—¬ ì‚¬ìš©ë˜ëŠ” 8ë¹„íŠ¸ ì–‘ìí™” ë¼ì´ë¸ŒëŸ¬ë¦¬
- ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ í†µí•´ ì–‘ìí™” ê´€ë ¨ ì„¤ì •ê°’ì„ ì§€ì •í•  ìˆ˜ ìˆìŒ
- ì˜ˆë¥¼ ë“¤ì–´ 
  - 4ë¹„íŠ¸ ë² ì´ìŠ¤ ëª¨ë¸ì„ ë¡œë”©
  -  4ë¹„íŠ¸ ëª¨ë¸ì˜ ì—°ì‚° ê³¼ì •ì—ì„œ ì‚¬ìš©í•  ë°ì´í„° íƒ€ì…ì„ ì§€ì •
  - ì–‘ìí™”ì˜ ìœ í˜•ì„ ëª…ì‹œë“±ì˜ ì„¸ë¶€ì ì¸ ì„¤ì •ì„ ì§„í–‰í•  ìˆ˜ ìˆìŒ

### Step 5. `TrainingArguments` íŒŒë¼ë¯¸í„° ì„¤ì •

```python
#ëª¨ë¸ì´ ì˜ˆì¸¡í•œ ê²°ê³¼ì™€ ì²´í¬í¬ì¸íŠ¸ê°€ ì €ì¥ë  ì¶œë ¥ ë””ë ‰í„°ë¦¬
output_dir = "./results" 

# í›ˆë ¨ ì—í¬í¬ ìˆ˜
num_train_epochs = 1 

# fp16/bf16 í•™ìŠµ í™œì„±í™”(A100ìœ¼ë¡œ bf16ì„ Trueë¡œ ì„¤ì •)
fp16 = False   
bf16 = False   

# í›ˆë ¨ìš© ë°°ì¹˜ í¬ê¸°
per_device_train_batch_size = 1 

# í‰ê°€ìš© ë°°ì¹˜ í¬ê¸°
per_device_eval_batch_size = 1  

# ê·¸ë˜ë””ì–¸íŠ¸ë¥¼ ëˆ„ì í•  ì—…ë°ì´íŠ¸ ìŠ¤í… íšŸìˆ˜
gradient_accumulation_steps = 1  

# ê·¸ë˜ë””ì–¸íŠ¸ ì²´í¬í¬ì¸íŠ¸ í™œì„±í™”
gradient_checkpointing = True  


# ê·¸ë˜ë””ì–¸íŠ¸ í´ë¦¬í•‘ì„ ìœ„í•œ ìµœëŒ€ ê·¸ë˜ë””ì–¸íŠ¸ ë…¸ë¦„ì„ ì„¤ì •. 
# ê·¸ë˜ë””ì–¸íŠ¸ í´ë¦¬í•‘ì€ ê·¸ë˜ë””ì–¸íŠ¸ì˜ í¬ê¸°ë¥¼ ì œí•œí•˜ì—¬ í›ˆë ¨ ì¤‘ ì•ˆì •ì„±ì„ ë†’ì„.
# Maximum gradient normal (ê·¸ë˜ë””ì–¸íŠ¸ í´ë¦¬í•‘) 0.3ìœ¼ë¡œ ì„¤ì •
max_grad_norm = 0.3  

# ì´ˆê¸° í•™ìŠµë¥  AdamW ì˜µí‹°ë§ˆì´ì €
learning_rate = 2e-6 

# bias/LayerNorm ê°€ì¤‘ì¹˜ë¥¼ ì œì™¸í•˜ê³  ëª¨ë“  ë ˆì´ì–´ì— ì ìš©í•  Weight decay ê°’
weight_decay = 0.001 

# ì˜µí‹°ë§ˆì´ì € ì„¤ì •
optim = "paged_adamw_32bit"  

# í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ëŸ¬ì˜ ìœ í˜• ì„¤ì •, ì—¬ê¸°ì„œëŠ” ì½”ì‚¬ì¸ ìŠ¤ì¼€ì¤„ëŸ¬ ì‚¬ìš©
lr_scheduler_type = "cosine"   

# í›ˆë ¨ ìŠ¤í… ìˆ˜(num_train_epochs ì¬ì •ì˜)
max_steps = -1 

# (0ë¶€í„° learning rateê¹Œì§€) í•™ìŠµ ì´ˆê¸°ì— í•™ìŠµë¥ ì„ ì ì§„ì ìœ¼ë¡œ ì¦ê°€ì‹œí‚¤ linear warmup ìŠ¤í…ì˜ Ratio
warmup_ratio = 0.03  

# ì‹œí€€ìŠ¤ë¥¼ ë™ì¼í•œ ê¸¸ì´ì˜ ë°°ì¹˜ë¡œ ê·¸ë£¹í™”, ë©”ëª¨ë¦¬ ì ˆì•½ ë° í›ˆë ¨ ì†ë„ë¥¼ ë†’ì„
group_by_length = True   

# X ì—…ë°ì´íŠ¸ ë‹¨ê³„ë§ˆë‹¤ ì²´í¬í¬ì¸íŠ¸ ì €ì¥
save_steps = 0  

# ë§¤ X ì—…ë°ì´íŠ¸ ìŠ¤í… ë¡œê·¸
logging_steps = 25  
```

- TrainerëŠ” í—ˆê¹…í˜ì´ìŠ¤ì—ì„œ ì œê³µí•˜ëŠ” ë¼ì´ë¸ŒëŸ¬ë¦¬ë¡œ ëª¨ë¸ì˜ í•™ìŠµë¶€í„° í‰ê°€ê¹Œì§€ í•œ ë²ˆì— í•´ê²°í•  ìˆ˜ ìˆëŠ” APIë¥¼ ì œê³µ
- `num_train_epchs` íŒŒë¼ë¯¸í„°ë¥¼ í†µí•´ ëª¨ë¸ì´ ì „ì²´ ë°ì´í„°ì…‹ì„ ëª‡ ë²ˆ ë°˜ë³µí•˜ì—¬ í•™ìŠµí•  ì§€ë¥¼ ì§€ì •
- `per_device_train_batch_size` ê° GPUì—ì„œ í•œ ë²ˆì— ì²˜ë¦¬í•  ë°ì´í„°ì˜ ì–‘
  - ì—¬ê¸°ì„œëŠ” ëª¨ë‘ 1ë¡œ ì§€ì •í•˜ì—¬ í•œ ë²ˆì— í•˜ë‚˜ì˜ ë°ì´í„°ë§Œ ì²˜ë¦¬í•˜ë„ë¡ ì„¤ì •
- `gradient_accumulation_steps` íŒŒë¼ë¯¸í„°ë¥¼ í†µí•´ ê¸°ìš¸ê¸°ë¥¼ ê°±ì‹ í•˜ê¸° ì „ì— ëª‡ ë²ˆì˜ ê¸°ìš¸ê¸° ì—…ë°ì´íŠ¸ë¥¼ ì¶•ì í• ì§€ë¥¼ ê²°ì •
  - ì—¬ê¸°ì„œëŠ” 1ë¡œ ì„¤ì •ë˜ì–´ ìˆì–´ ë§¤ ìŠ¤í…ë§ˆë‹¤ ê¸°ìš¸ê¸°ë¥¼ ê°±ì‹ 
- `gradient_checkpointing` íŒŒë¼ë¯¸í„°ë¥¼ í†µí•´ ë©”ëª¨ë¦¬ ì‚¬ìš©ì„ ìµœì í™”
  - ëŒ€ê·œëª¨ ëª¨ë¸ì„ ì‚¬ìš©í•  ë•Œ íŠ¹íˆ ìœ ìš©í•œ íŒŒë¼ë¯¸í„°ë¡œì„œ í•„ìš”í•  ë•Œë§Œ íŠ¹ì • ê³„ì¸µì˜ ê¸°ìš¸ê¸°ë¥¼ ì €ì¥í•˜ê³  ë‚˜ë¨¸ì§€ëŠ” ë²„ë ¤ ë©”ëª¨ë¦¬ì˜ ë¶€ë‹´ì„ ì¤„ì„
- `max_grad_norm` íŒŒë¼ë¯¸í„°ë¥¼ í†µí•´ ëª¨ë¸ì´ ë°ì´í„°ë¡œë¶€í„° í•™ìŠµí•˜ëŠ” ì†ë„ë¥¼ ì¡°ì ˆ, ê¸°ìš¸ê¸°ê°€ ê³¼ë„í•˜ê²Œ ì»¤ì ¸ì„œ ë°œìƒí•  ìˆ˜ ìˆëŠ” **gradient exploding** ë¬¸ì œ ë“±ì„ ë°©ì§€í•  ìˆ˜ ìˆë„ë¡ ê¸°ìš¸ê¸°ì˜ ìµœëŒ€ í¬ê¸°ë¥¼ ì„¤ì •
- **Adam** ì˜µí‹°ë§ˆì´ì €ë¥¼ ì‚¬ìš©í•˜ì—¬ `learning_rate`ë¥¼ ë³´ìˆ˜ì ìœ¼ë¡œ ì¡ì•„ ëª¨ë¸ì´ ë°ì´í„°ë¡œë¶€í„° í•™ìŠµí•˜ëŠ” ì†ë„ë¥¼ ì ì ˆíˆ ëŠ¦ì¶”ë„ë¡ ì„¤ì •
- weight_decay ê°’ì„ ì ì ˆíˆ ì£¼ì–´ ëª¨ë¸ì˜ ê°€ì¤‘ì¹˜ê°€ ë„ˆë¬´ í° ê°’ì„ ê°€ì§€ì§€ ì•Šë„ë¡ í•¨ìœ¼ë¡œì„œ ì˜¤ë²„í”¼íŒ… í˜„ìƒì„ í•´ì†Œ
  - ìŠ¤ì¼€ì¤„ëŸ¬ëŠ” **Cosine Decay**ë¥¼ ì‚¬ìš©í•˜ì—¬ ì•ˆì •ì ìœ¼ë¡œ ëŠê¹€ì—†ì´ Lossê°€ ê°ì†Œí•˜ë„ë¡ í•  ê²ƒì´ë‹¤.

### Step 6. SFT íŒŒë¼ë¯¸í„° ê°’ ì„¤ì •

```py
# ìµœëŒ€ ì‹œí€€ìŠ¤ ê¸¸ì´ ì„¤ì •
max_seq_length = None 

# ë™ì¼í•œ ì…ë ¥ ì‹œí€€ìŠ¤ì— ì—¬ëŸ¬ ê°œì˜ ì§§ì€ ì˜ˆì œë¥¼ ë„£ì–´ íš¨ìœ¨ì„±ì„ ë†’ì¼ ìˆ˜ ìˆìŒ
packing = False  

# GPU 0 ì „ì²´ ëª¨ë¸ ë¡œë“œ 
device_map = {"": 0}  
```

- SFTëŠ” ë¼ë²¨ëŸ¬ë“¤ì´ ì œì‘í•œ í”„ë¡¬í”„íŠ¸ ë°ì´í„°ì…‹ì„ ì´ìš©í•˜ì—¬ ë² ì´ìŠ¤ ëª¨ë¸ì„ ì§€ë„í•™ìŠµ ë°”íƒ•ìœ¼ë¡œ íŒŒì¸ íŠœë‹í•˜ëŠ” ê¸°ë²•ìœ¼ë¡œ, ì£¼ì–´ì§„ ì¼ì • í† í°ì— ëŒ€í•œ ë‹¤ìŒ í† í°ì„ ì˜ˆì¸¡í•˜ëŠ” í˜•ì‹ìœ¼ë¡œ ì§„í–‰ëœë‹¤.
- `max_seq_length`ëŠ” ì…ë ¥ ì‹œí€€ìŠ¤ì— ëŒ€í•œ ìµœëŒ€ ì‚¬ì´ì¦ˆë¥¼ ì˜ë¯¸
  - ì˜ˆë¥¼ ë“¤ì–´ ë¬¸ì¥ 2ê°œê°€ í•©ì³ì§ˆ ë•Œ maximum sequenceê°€ ì–´ëŠ ì •ë„ì¼ì§€ë¥¼ ê²°ì •
- `packing` ì´ë€ í›ˆë ¨ê³¼ì •ì—ì„œì˜ íš¨ìœ¨ì„±ì„ ë†’ì´ê¸° ìœ„í•´ ë³µìˆ˜ ê°œì˜ ì˜ˆì‹œ ë¬¸ì¥ì„ í•˜ë‚˜ì˜ Input ì‹œí€€ìŠ¤ë¡œ ë„£ì–´ì£¼ëŠ” ê¸°ë²•
- `device_map`ì„ í†µí•´ ëª‡ ë²ˆ GPUë¥¼ ë¡œë“œí•  ì§€ ì§€ì •

### Step 7. ë°ì´í„° ì„¸íŠ¸ ë¡œë”©ê³¼ ë°ì´í„° íƒ€ì… ê²°ì •

```py
dataset = load_dataset(dataset_name, split="train")
```

```py

compute_dtype = getattr(torch, bnb_4bit_compute_dtype)
# ëª¨ë¸ ê³„ì‚°ì— ì‚¬ìš©ë  ë°ì´í„° íƒ€ì… ê²°ì •
bnb_config = BitsAndBytesConfig(
    load_in_4bit=use_4bit,  # ëª¨ë¸ì„ 4ë¹„íŠ¸ë¡œ ë¡œë“œí• ì§€ ì—¬ë¶€ë¥¼ ê²°ì •
    bnb_4bit_quant_type=bnb_4bit_quant_type, # ì–‘ìí™” ìœ í˜•ì„ ì„¤ì •
    bnb_4bit_compute_dtype=compute_dtype,  # ê³„ì‚°ì— ì‚¬ìš©ë  ë°ì´í„° íƒ€ì…ì„ ì„¤ì •
    bnb_4bit_use_double_quant=use_nested_quant, # ì¤‘ì²© ì–‘ìí™”ë¥¼ ì‚¬ìš©í• ì§€ ì—¬ë¶€ë¥¼ ê²°ì •
)
```

- SFTë¥¼ ì§„í–‰í•˜ê¸° ìœ„í•œ ë°ì´í„°ì…‹ì„ ë¡œë“œ BitsAndBytesConfig ì¸ìŠ¤í„´ìŠ¤ë¥¼ ìƒì„±í•  ë•Œ ì•ì„œ ì‚´í´ë³´ì•˜ë˜ ë°ì´í„° ì…ì„ ì£¼ì…

### Step 8. GPU í˜¸í™˜ì„± í™•ì¸

```py

# ë§Œì•½ GPUê°€ ìµœì†Œí•œ ë²„ì „ 8 ì´ìƒì´ë¼ë©´ (major >= 8) bfloat16ì„ ì§€ì›í•œë‹¤ê³  ë©”ì‹œì§€ë¥¼ ì¶œë ¥. 
# bfloat16ì€ í›ˆë ¨ ì†ë„ë¥¼ ë†’ì¼ ìˆ˜ ìˆëŠ” ë°ì´í„° íƒ€ì…. 

if compute_dtype == torch.float16 and use_4bit:
    major, _ = torch.cuda.get_device_capability()
    if major >= 8:
        print("=" * 80)
        print("Your GPU supports bfloat16: accelerate training with bf16=True")
        print("=" * 80)
```

- í˜„ì¬ GPUê°€ bfloat16 í˜•íƒœë¥¼ ì§€ì›í•˜ëŠ” ì§€ í™•ì¸í•œë‹¤. ë§Œì•½ GPUì˜ CUDA ë²„ì „ì´ 8 ì´ìƒì´ë¼ë©´ í•´ë‹¹ ë°ì´í„° íƒ€ì…ì„ ì§€ì›í•˜ëŠ” ê²ƒì´ë‹¤.
- bfloat16ì´ë€ ëª¨ë¸ì˜ íŠ¸ë ˆì´ë‹ ì†ë„ë¥¼ ë†’ì¼ ìˆ˜ ìˆëŠ” ë°ì´í„° íƒ€ì…ìœ¼ë¡œì„œ, 16ë¹„íŠ¸ ë¶€ë™ ì†Œìˆ˜ì  í˜•ì‹ì„ ë‚˜íƒ€ë‚¸ë‹¤.
-  ë¬¼ë¡  **32ë¹„íŠ¸ ë¶€ë™ ì†Œìˆ˜ì  í˜•ì‹ë³´ë‹¤ëŠ” ì •í™•ë„ê°€ ë¹„êµì  ë–¨ì–´ì§€ì§€ë§Œ** ë©”ëª¨ë¦¬ ìš”êµ¬ ì‚¬í•­ì´ ì ë‹¤ëŠ” ì ì—ì„œ ëª¨ë¸ í•™ìŠµì— ìœ ìš©í•˜ë‹¤ê³  í•  ìˆ˜ ìˆë‹¤.

### Step 9. ë² ì´ìŠ¤ ëª¨ë¸ ë¡œë”©

- ë² ì´ìŠ¤ ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì €ë¥¼ ë¡œë“œí•œ ë‹¤ìŒ LoRA ì—°ì‚°ì„ ì ìš©

```py
# Load base model
model = AutoModelForCausalLM.from_pretrained(
    model_name,
    quantization_config=bnb_config,
    device_map=device_map
)
model.config.use_cache = False
model.config.pretraining_tp = 1

# Load LLaMA tokenizer
tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)

# ë™ì¼í•œ batch ë‚´ì—ì„œ ì…ë ¥ì˜ í¬ê¸°ë¥¼ ë™ì¼í•˜ê¸° ìœ„í•´ì„œ ì‚¬ìš©í•˜ëŠ” Padding Tokenì„ End of Sequenceë¼ê³  í•˜ëŠ” Special Tokenìœ¼ë¡œ ì‚¬ìš©í•œë‹¤.
tokenizer.pad_token = tokenizer.eos_token
tokenizer.padding_side = "right" # Fix weird overflow issue with fp16 training. Paddingì„ ì˜¤ë¥¸ìª½ ìœ„ì¹˜ì— ì¶”ê°€í•œë‹¤.

# Load LoRA configuration
peft_config = LoraConfig(
    lora_alpha=lora_alpha,
    lora_dropout=lora_dropout,
    r=lora_r,
    bias="none",
    task_type="CAUSAL_LM", # íŒŒì¸íŠœë‹í•  íƒœìŠ¤í¬ë¥¼ Optionalë¡œ ì§€ì •í•  ìˆ˜ ìˆëŠ”ë°, ì—¬ê¸°ì„œëŠ” CASUAL_LMì„ ì§€ì •í•˜ì˜€ë‹¤.
)

# Set training parameters
training_arguments = TrainingArguments(
    output_dir=output_dir,
    num_train_epochs=num_train_epochs,
    per_device_train_batch_size=per_device_train_batch_size,
    gradient_accumulation_steps=gradient_accumulation_steps,
    optim=optim,
    save_steps=save_steps,
    logging_steps=logging_steps,
    learning_rate=learning_rate,
    weight_decay=weight_decay,
    fp16=fp16,
    bf16=bf16,
    max_grad_norm=max_grad_norm,
    max_steps=max_steps,
    warmup_ratio=warmup_ratio,
    group_by_length=group_by_length,
    lr_scheduler_type=lr_scheduler_type,
    report_to="tensorboard"
)

# Set supervised fine-tuning parameters
trainer = SFTTrainer(
    model=model,
    train_dataset=dataset,
    peft_config=peft_config,
    dataset_text_field="text",
    max_seq_length=max_seq_length,
    tokenizer=tokenizer,
    args=training_arguments,
    packing=packing,
)
```

### Step 10. ëª¨ë¸ í›ˆë ¨ê³¼ í›ˆë ¨ëœ ëª¨ë¸ ì €ì¥

- ëª¨ë¸ì„ ì €ì¥í•˜ë©´ base_model íŒŒë¼ë¯¸í„°ë¥¼ ì œì™¸í•œ Adapter ë¶€ë¶„ë§Œ ì €ì¥ ëœ ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤.

  

- `trainer` ê°ì²´ëŠ” ì´ì „ì— ì •ì˜ëœ ì—¬ëŸ¬ ì„¤ì •(ëª¨ë¸, ë°ì´í„° ì„¸íŠ¸, í›ˆë ¨ íŒŒë¼ë¯¸í„° ë“±)ì„ í¬í•¨í•œë‹¤.

- `train` ë©”ì„œë“œë¥¼ í†µí•´ ë°ì´í„°ì„¸íŠ¸ë¥¼ ë°˜ë³µì ìœ¼ë¡œ ì²˜ë¦¬í•˜ë©´ì„œ ëª¨ë¸ì˜ ê°€ì¤‘ì¹˜ë¥¼ ì—…ë°ì´íŠ¸í•˜ëŠ” ëª¨ìŠµì„ ë³¼ ìˆ˜ ìˆë‹¤.

```py
trainer.train()

# í›ˆë ¨ì´ ì™„ë£Œëœ ëª¨ë¸ì„ 'new_model'ì— ì €ì¥ 
trainer.model.save_pretrained(new_model) 
```

### Step 11. ëª¨ë¸ ì´ë¦„ ì¶œë ¥, ê¸°ë³¸ ëª¨ë¸ ì¬ë¡œë”© í›„ LoRA ê°€ì¤‘ì¹˜ì™€ì˜ í†µí•©

- í•™ìŠµëœ LoRA adapter ê°€ì¤‘ì¹˜ë¥¼ ì›ë³¸ ëª¨ë¸ì— ë³‘í•©í•˜ëŠ” `merge_and_unload` ë©”ì„œë“œë¥¼ í™œìš©í•´ **ëª¨ë¸ê³¼ LoRAë¥¼ ë”°ë¡œ ë¶ˆëŸ¬ì™€ ë§¤í•‘í•˜ì§€ ì•Šê³  í•˜ë‚˜ì˜ ëª¨ë¸ë¡œ í™œìš©**
- LoRA ì–´ëŒ‘í„°ë¥¼ í†µí•´ ì–»ì€ íŒŒì¸íŠœë‹ì˜ ê²°ê³¼ë¬¼ í¬ê¸°ëŠ” ëª‡ MBë°–ì— ë˜ì§€ ì•ŠëŠ”ë‹¤.
- ì´ëŸ¬í•œ ì–´ëŒ‘í„°ë¥¼ ì‚¬ì „ í›ˆë ¨ëœ ëª¨ë¸ì— `merge_and_unload` í•œ ì¤„ë¡œ ë³‘í•©í•˜ê³  í•´ë‹¹ ëª¨ë¸ì„ ë°°í¬í•œë‹¤.
- ì´ëŸ¬í•œ ì–´ëŒ‘í„° íŒ¨í„´ì˜ ì¥ì ì€ íŠ¹ì •í•œ íƒœìŠ¤í¬ì— ë”°ë¼ íŒŒì¸íŠœë‹ ëœ ì–´ëŒ‘í„°ë¥¼ ìœ ì—°í•˜ê²Œ ì„¤ì •í•  ìˆ˜ ìˆë‹¤.

```py
# base_modelê³¼ new_modelì— ì €ì¥ëœ LoRA ê°€ì¤‘ì¹˜ë¥¼ í†µí•©í•˜ì—¬ ìƒˆë¡œìš´ ëª¨ë¸ì„ ìƒì„±
base_model = AutoModelForCausalLM.from_pretrained(
    model_name,
    low_cpu_mem_usage=True,
    return_dict=True,
    torch_dtype=torch.float16
)
model = PeftModel.from_pretrained(base_model, new_model) # LoRA ê°€ì¤‘ì¹˜ë¥¼ ê°€ì ¸ì™€ ê¸°ë³¸ ëª¨ë¸ì— í†µí•©
```

```py
model = model.merge_and_unload()
```

```py
# ì‚¬ì „ í›ˆë ¨ëœ í† í¬ë‚˜ì´ì €ë¥¼ ë‹¤ì‹œ ë¡œë“œ
tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)  

# í† í¬ë‚˜ì´ì €ì˜ íŒ¨ë”© í† í°ì„ ì¢…ë£Œ í† í°(end-of-sentence token)ê³¼ ë™ì¼í•˜ê²Œ ì„¤ì •
tokenizer.pad_token = tokenizer.eos_token  

# íŒ¨ë”©ì„ ì‹œí€€ìŠ¤ì˜ ì˜¤ë¥¸ìª½ì— ì ìš©
tokenizer.padding_side = "right"  
```

### Step 12. Hugging Face Hub ë¡œê·¸ì¸ ì—…ë¡œë“œ

```py
from huggingface_hub import interpreter_login

interpreter_login()
```

```python
model.push_to_hub(new_model, use_temp_dir=False)
tokenizer.push_to_hub(new_model, use_temp_dir=False)
```

